{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323666e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import math\n",
    "from typing import TypedDict, Annotated, List, Dict, Any\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# ‚úÖ SQLite checkpointer\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from utils.tools import TOOLS\n",
    "\n",
    "def save_graph_image(graph, filename=\"Topic3_task5.png\"):\n",
    "    \"\"\"\n",
    "    Generate a Mermaid diagram of the graph and save it as a PNG image.\n",
    "    Uses the graph's built-in Mermaid export functionality.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the Mermaid PNG representation of the graph\n",
    "        # This requires the 'grandalf' package for rendering\n",
    "        png_data = graph.get_graph(xray=True).draw_mermaid_png()\n",
    "\n",
    "        # Write the PNG data to file\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(png_data)\n",
    "\n",
    "        print(f\"Graph image saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save graph image: {e}\")\n",
    "        print(\"You may need to install additional dependencies: pip install grandalf\")\n",
    "\n",
    "# =========================================================\n",
    "# STATE\n",
    "# =========================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    should_exit: bool\n",
    "    verbose: bool\n",
    "    is_empty: bool\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# NODE: Get user input\n",
    "# =========================================================\n",
    "\n",
    "def get_user_input(state: AgentState) -> dict:\n",
    "    if state.get(\"verbose\", False):\n",
    "        print(\"[TRACE] Entering get_user_input\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Tool-Using Chat Agent (LangGraph) - Single Long Conversation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Commands: verbose | quiet | quit/exit/q\")\n",
    "    print()\n",
    "\n",
    "    raw = input(\"> \").strip()\n",
    "\n",
    "    if raw.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        return {\"should_exit\": True, \"is_empty\": False}\n",
    "\n",
    "    if raw == \"\":\n",
    "        return {\"is_empty\": True, \"should_exit\": False}\n",
    "\n",
    "    if raw.lower() == \"verbose\":\n",
    "        print(\"Verbose mode ENABLED\")\n",
    "        return {\"verbose\": True, \"is_empty\": True, \"should_exit\": False}\n",
    "\n",
    "    if raw.lower() == \"quiet\":\n",
    "        print(\"Verbose mode DISABLED\")\n",
    "        return {\"verbose\": False, \"is_empty\": True, \"should_exit\": False}\n",
    "\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=raw)],\n",
    "        \"should_exit\": False,\n",
    "        \"is_empty\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# GRAPH CREATION (assistant + tools + print + loop)\n",
    "# =========================================================\n",
    "\n",
    "def create_graph(checkpointer: SqliteSaver, model: str = \"gpt-4o-mini\"):\n",
    "    system_msg = SystemMessage(content=(\n",
    "        \"You are a helpful assistant that can use tools.\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"- Never guess coordinates or counts; always use tools.\\n\"\n",
    "        \"- Use count_letter_tool for letter counting.\\n\"\n",
    "        \"- Use sin_tool for sin(x).\\n\"\n",
    "        \"- Use calculator_tool for add/sub/mul/div if needed.\\n\"\n",
    "        \"- Use I-64 tools for city list/coords/distance.\\n\"\n",
    "        \"- Keep answers brief and show key numbers.\"\n",
    "    ))\n",
    "\n",
    "    llm = ChatOpenAI(model=model, temperature=0).bind_tools(TOOLS)\n",
    "    tool_node = ToolNode(TOOLS)\n",
    "\n",
    "    def route_after_input(state: AgentState) -> str:\n",
    "        if state.get(\"should_exit\", False):\n",
    "            return END\n",
    "        if state.get(\"is_empty\", False):\n",
    "            return \"get_user_input\"\n",
    "        return \"assistant\"\n",
    "    \n",
    "    def route_after_assistant(state: AgentState) -> str:\n",
    "        last = state[\"messages\"][-1]\n",
    "        if hasattr(last, \"tool_calls\") and last.tool_calls:\n",
    "            return \"tools\"\n",
    "        return \"print_response\"\n",
    "\n",
    "    def assistant(state: AgentState) -> dict:\n",
    "        msgs = state.get(\"messages\", [])\n",
    "        if not msgs or getattr(msgs[0], \"type\", None) != \"system\":\n",
    "            msgs = [system_msg] + msgs\n",
    "        ai = llm.invoke(msgs)\n",
    "        return {\"messages\": [ai]}\n",
    "\n",
    "    def print_response(state: AgentState) -> dict:\n",
    "        last = state[\"messages\"][-1]\n",
    "        if getattr(last, \"type\", None) in (\"ai\", \"assistant\"):\n",
    "            print(\"\\n\" + \"-\" * 60)\n",
    "            print(\"Assistant:\")\n",
    "            print(\"-\" * 60)\n",
    "            print(last.content)\n",
    "        return {}\n",
    "\n",
    "    g = StateGraph(AgentState)\n",
    "\n",
    "    g.add_node(\"get_user_input\", get_user_input)\n",
    "    g.add_node(\"assistant\", assistant)\n",
    "    g.add_node(\"tools\", tool_node)\n",
    "    g.add_node(\"print_response\", print_response)\n",
    "\n",
    "    g.add_edge(START, \"get_user_input\")\n",
    "\n",
    "    # Decide whether to exit / ask again / call assistant\n",
    "    g.add_conditional_edges(\n",
    "        \"get_user_input\",\n",
    "        route_after_input,\n",
    "        {\n",
    "            \"assistant\": \"assistant\",\n",
    "            \"get_user_input\": \"get_user_input\",\n",
    "            END: END,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Tool loop (assistant -> tools? -> assistant)\n",
    "    g.add_conditional_edges(\"assistant\", tools_condition)\n",
    "    g.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "    # After the assistant finishes (no more tools), print and return to input\n",
    "    # g.add_edge(\"assistant\", \"print_response\")\n",
    "    \n",
    "    g.add_conditional_edges(\n",
    "        \"assistant\",\n",
    "        route_after_assistant,\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            \"print_response\": \"print_response\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    g.add_edge(\"tools\", \"assistant\")\n",
    "    g.add_edge(\"print_response\", \"get_user_input\")\n",
    "\n",
    "    return g.compile(checkpointer=checkpointer)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# MAIN (resume / start with crash recovery)\n",
    "# =========================================================\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(add_help=True)\n",
    "    parser.add_argument(\n",
    "        \"--thread\",\n",
    "        default=os.environ.get(\"LANGGRAPH_THREAD_ID\", \"chat-1\"),\n",
    "        help=\"Conversation thread_id (same id => resume from checkpoints)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--db\",\n",
    "        default=os.environ.get(\"LANGGRAPH_CHECKPOINT_DB\", \"tool_chat_checkpoints.db\"),\n",
    "        help=\"SQLite checkpoint DB file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        default=os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "        help=\"OpenAI chat model name (default: gpt-4o-mini)\",\n",
    "    )\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"LangGraph: Tool-Using Chat Agent (Single Long Conversation)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Checkpoint DB: {args.db}\")\n",
    "    print(f\"Thread ID:     {args.thread}\")\n",
    "    print(f\"Model:         {args.model}\")\n",
    "    print()\n",
    "\n",
    "    with SqliteSaver.from_conn_string(args.db) as checkpointer:\n",
    "        graph = create_graph(checkpointer=checkpointer, model=args.model)\n",
    "        config = {\"configurable\": {\"thread_id\": args.thread}}\n",
    "\n",
    "        save_graph_image(graph, filename=\"Topic3_task5.png\")\n",
    "        # Resume if there is unfinished work\n",
    "        current = graph.get_state(config)\n",
    "        if getattr(current, \"next\", None):\n",
    "            print(\"üîÑ Found saved state. Resuming from last checkpoint...\\n\")\n",
    "            graph.invoke(None, config=config)\n",
    "        else:\n",
    "            print(\"‚ñ∂Ô∏è  Starting a new conversation...\\n\")\n",
    "            initial_state: AgentState = {\n",
    "                \"messages\": [SystemMessage(content=\"(system placeholder)\")]\n",
    "                , \"should_exit\": False\n",
    "                , \"verbose\": False\n",
    "                , \"is_empty\": False\n",
    "            }\n",
    "            graph.invoke(initial_state, config=config)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
